{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59601681-35ad-4c84-bfa2-8711aab41a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adudi/Documents/projects/ollama_agent/venv/lib/python3.10/site-packages/gradio/components/chatbot.py:288: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "Could not create share link. Missing file: /Users/adudi/Documents/projects/ollama_agent/venv/lib/python3.10/site-packages/gradio/frpc_darwin_arm64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.3\n",
      "3. Move the file to this location: /Users/adudi/Documents/projects/ollama_agent/venv/lib/python3.10/site-packages/gradio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ChatMessageHistory\n",
    "import gradio as gr\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "def respond(message, history):\n",
    "    chat_history.add_user_message(message)\n",
    "    response = chain.invoke({\"messages\": chat_history.messages})\n",
    "    chat_history.add_ai_message(response.content)\n",
    "    return \"Bot: \" + response.content\n",
    "\n",
    "chat_interface = gr.ChatInterface(fn=respond)\n",
    "chat_interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9880fd-d367-4236-82a7-9917d74c8d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ownership of Super Bowl LVIII (58) in 2025 has not been officially announced by the National Football League (NFL). However, the NFL typically announces the host city and stadium for each Super Bowl several years in advance.\n",
      "\n",
      "As of now, there have been no official announcements regarding the location or ownership of Super Bowl LVIII. The NFL usually makes these announcements at their annual Fall Meeting, which takes place in September or October.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Who own 2025 {sport}?\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"sport\": \"superbowl\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df8f1ce-57dc-490e-b7af-ad8d01cdbfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here is the translation:\\n\\nJ\\'adore le programmation.\\n\\nNote: \"programmation\" is a noun, so it\\'s capitalized in French.', additional_kwargs={}, response_metadata={'model': 'llama3', 'created_at': '2025-02-10T22:59:44.812291Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4008311792, 'load_duration': 578571250, 'prompt_eval_count': 22, 'prompt_eval_duration': 1782000000, 'eval_count': 32, 'eval_duration': 1646000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-84fa2bad-635c-4cb0-aa10-36e8d86aabab-0', usage_metadata={'input_tokens': 22, 'output_tokens': 32, 'total_tokens': 54})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to French: I love programming.\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d58a1c-0787-4490-ad51-d4836ee34f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I apologize, but this conversation has just started. I haven't said anything yet! I'm here to help answer your questions or have a chat with you. What would you like to talk about?\", additional_kwargs={}, response_metadata={'model': 'llama3', 'created_at': '2025-02-10T23:01:33.55896Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2798170542, 'load_duration': 34075458, 'prompt_eval_count': 16, 'prompt_eval_duration': 620000000, 'eval_count': 41, 'eval_duration': 2143000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-b0ee28e7-aabf-4341-aa48-c519b9fa88f8-0', usage_metadata={'input_tokens': 16, 'output_tokens': 41, 'total_tokens': 57})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the model on its own does not have any concept of state\n",
    "\n",
    "llm.invoke([HumanMessage(content=\"What did you just say?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ada709-2141-4d7b-bce4-4f64b77b02f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I translated the sentence \"I love programming\" from English to French, and the French equivalent is:\\n\\nJ\\'adore la programmation.\\n\\nWhich means: I adore (or really enjoy) programming.', additional_kwargs={}, response_metadata={'model': 'llama3', 'created_at': '2025-02-10T23:03:19.197847Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3371904833, 'load_duration': 36969833, 'prompt_eval_count': 46, 'prompt_eval_duration': 922000000, 'eval_count': 41, 'eval_duration': 2141000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f8e01d64-df7d-4a1f-82b3-4e97e8f4db3f-0', usage_metadata={'input_tokens': 46, 'output_tokens': 41, 'total_tokens': 87})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get around this, we need to pass in the entire conversation history into the model as context \n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to French: I love programming.\"\n",
    "        ),\n",
    "        AIMessage(content=\"J'adore la programmation.\"),\n",
    "        HumanMessage(content=\"What did you just say?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9af6f84-e272-4499-8f2c-038961f1c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a515fe94-ddf2-463f-9276-5f7ef513c364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The translation of \"I love programming\" in French is:\\n\\nJ\\'adore le programmation.\\n\\nHere\\'s a breakdown of the translation:\\n\\n* \"I\" becomes \"J\\'\" (je)\\n* \"love\" becomes \"adore\"\\n* \"programming\" becomes \"le programmation\"\\n\\nNote: \"le\" is used because \"programmation\" starts with a vowel sound, so it takes an indefinite article \"le\" instead of \"la\".', additional_kwargs={}, response_metadata={'model': 'llama3', 'created_at': '2025-02-10T23:07:25.374022Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6397327875, 'load_duration': 81974792, 'prompt_eval_count': 43, 'prompt_eval_duration': 1346000000, 'eval_count': 92, 'eval_duration': 4968000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-4b337d74-c013-4cd5-bec9-721fe7887050-0', usage_metadata={'input_tokens': 43, 'output_tokens': 92, 'total_tokens': 135})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\n",
    "    \"Translate this sentence from English to French: I love programming.\"\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"messages\": chat_history.messages})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "858f0a45-8a68-4be2-914f-6a9f5a96b284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The translation of \"I love programming\" in French is:\\n\\nJ\\'adore le programmation.\\n\\nHere\\'s a breakdown of the translation:\\n\\n* \"I\" becomes \"J\\'\" (je)\\n* \"love\" becomes \"adore\"\\n* \"programming\" becomes \"le programmation\"\\n\\nNote: \"le\" is used because \"programmation\" starts with a vowel sound, so it takes an indefinite article \"le\" instead of \"la\".'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48df4375-6394-4c62-b1ab-eaa34cb0e5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I translated the sentence \"I love programming\" from English to French. The translation is:\\n\\nJ\\'adore le programmation.\\n\\nLet me know if you need any further assistance!', additional_kwargs={}, response_metadata={'model': 'llama3', 'created_at': '2025-02-10T23:09:44.508661Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2298417958, 'load_duration': 31807375, 'prompt_eval_count': 149, 'prompt_eval_duration': 363000000, 'eval_count': 37, 'eval_duration': 1900000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-38cc9a16-1f8a-4d80-8981-30406e85cbfd-0', usage_metadata={'input_tokens': 149, 'output_tokens': 37, 'total_tokens': 186})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.add_ai_message(response.content)\n",
    "chat_history.add_user_message(\"What did you say?\")\n",
    "chain.invoke({\"messages\": chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c516290-234e-47e1-9977-36ee7673a39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adudi/Documents/projects/ollama_agent/venv/lib/python3.10/site-packages/gradio/components/chatbot.py:288: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Missing file: /Users/adudi/Documents/projects/ollama_agent/venv/lib/python3.10/site-packages/gradio/frpc_darwin_arm64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.3\n",
      "3. Move the file to this location: /Users/adudi/Documents/projects/ollama_agent/venv/lib/python3.10/site-packages/gradio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def respond(message, history):\n",
    "    chat_history.add_user_message(message)\n",
    "    response = chain.invoke({\"messages\": chat_history.messages})\n",
    "    chat_history.add_ai_message(response.content)\n",
    "    return \"Bot: \" + response.content\n",
    "\n",
    "chat_interface = gr.ChatInterface(fn=respond)\n",
    "chat_interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a67d25-3abf-43ab-873d-8d3d2b988dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "data = loader.load()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c16fe8-4e41-4e17-aaba-02251ae7dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05f71d24-8e4e-4af6-b7ac-502e33ea3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OllamaEmbeddings(model=\"llama3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6cdbd93-61d6-4656-863c-dd4140725dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8fb2ee91-7b8a-42b9-8516-91fd84728282', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.'),\n",
       " Document(id='a45e9e58-a375-4bc5-9d9d-8f01881694f4', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Prompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.'),\n",
       " Document(id='a62d2afe-f4c3-406a-9e70-18bbe5d96838', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started with LangSmith | 🦜️🛠️ LangSmith'),\n",
       " Document(id='8fd2c8ce-e8d7-4dbc-a948-3d5924438bc2', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k is the number of chunks to retrieve\n",
    "retriever = vectorstore.as_retriever(k=4)\n",
    "\n",
    "docs = retriever.invoke(\"how can langsmith help with testing?\")\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15de25f1-c4ec-4eeb-92aa-eaecbac839cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions using this context: \\n\\n{context}\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b85ee7bd-8ca5-44bb-9660-12cd6ac8bd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided context, LangSmith helps with testing through its Evals feature. This allows you to build and run high-quality evaluations easily, which is crucial for testing and optimizing your AI applications. With LangSmith, you can create dashboards to view key metrics like RPS (requests per second), error rates, and costs, giving you a better understanding of how your application performs.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"how can langsmith help with testing?\")\n",
    "\n",
    "document_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "        \"context\": docs,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b335f1ed-e15a-453b-bc07-c459a811516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def parse_retriever_input(params: Dict):\n",
    "    return params[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=parse_retriever_input | retriever,\n",
    ").assign(\n",
    "    answer=document_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f0799d6-d65b-41b9-bfc2-1395affbbe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how can langsmith help with testing?', additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(id='8fb2ee91-7b8a-42b9-8516-91fd84728282', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.'),\n",
       "  Document(id='a45e9e58-a375-4bc5-9d9d-8f01881694f4', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Prompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.'),\n",
       "  Document(id='a62d2afe-f4c3-406a-9e70-18bbe5d96838', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started with LangSmith | 🦜️🛠️ LangSmith'),\n",
       "  Document(id='8fd2c8ce-e8d7-4dbc-a948-3d5924438bc2', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.')],\n",
       " 'answer': \"According to the context, LangSmith's Evals feature makes building and running high-quality evaluations easy, which is crucial for testing AI applications. This means that LangSmith provides a set of tools to help you test your AI applications efficiently and effectively.\\n\\nWith LangSmith's Evals, you can:\\n\\n* Create high-quality evaluation datasets\\n* Test and optimize your AI applications quickly\\n\\nBy using LangSmith's Evals feature, you can ensure the quality and development speed of your AI applications are optimal.\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e05b8d6d-1c1d-4793-b4ad-f7d33a3c5c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how can langsmith help with testing?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"According to the context, LangSmith's Evals feature makes building and running high-quality evaluations easy, which is crucial for testing AI applications. This means that LangSmith provides a set of tools to help you test your AI applications efficiently and effectively.\\n\\nWith LangSmith's Evals, you can:\\n\\n* Create high-quality evaluation datasets\\n* Test and optimize your AI applications quickly\\n\\nBy using LangSmith's Evals feature, you can ensure the quality and development speed of your AI applications are optimal.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='tell me more about that!', additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(id='8fb2ee91-7b8a-42b9-8516-91fd84728282', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.'),\n",
       "  Document(id='a62d2afe-f4c3-406a-9e70-18bbe5d96838', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started with LangSmith | 🦜️🛠️ LangSmith'),\n",
       "  Document(id='8fd2c8ce-e8d7-4dbc-a948-3d5924438bc2', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.'),\n",
       "  Document(id='fe8f70f3-b7b4-440e-9de4-0c5265952b71', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.')],\n",
       " 'answer': \"According to LangSmith's documentation, their Evals feature is designed to help you build and run high-quality evaluations for your AI applications.\\n\\nHere are some ways LangSmith's Evals can help with testing:\\n\\n1. **Evaluation datasets**: Create evaluation datasets tailored to your specific use case or application. This ensures that your evaluation metrics are relevant and accurate.\\n2. **Metrics and KPIs**: Define the metrics and Key Performance Indicators (KPIs) that matter most for your application's performance, such as RPS (requests per second), error rates, and costs.\\n3. **Evaluation workflows**: Set up workflows to automate the evaluation process, ensuring consistency and efficiency in testing your AI applications.\\n\\nBy using LangSmith's Evals feature, you can:\\n\\n* Test and optimize your AI applications quickly\\n* Get meaningful insights from your application's performance\\n* Ensure high-quality evaluations that reflect real-world scenarios\\n\\nThis should help you build more robust and effective AI applications, which is a crucial step in developing and deploying successful AI-powered solutions.\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"tell me more about that!\")\n",
    "\n",
    "retrieval_chain.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3a88f9d-dc34-4635-8d09-1f23619465d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to the context, LangSmith's Evals feature helps with testing by providing a set of tools for building and running high-quality evaluations. This means that LangSmith has native support for evaluating AI models, making it easier to test and optimize your applications.\\n\\nHere are some potential benefits of using LangSmith's Evals:\\n\\n* **Efficient evaluation**: LangSmith's Evals allows you to create and run evaluations quickly, which can save you time and effort in testing your AI applications.\\n* **High-quality datasets**: With LangSmith, you can easily create high-quality evaluation datasets that accurately test your AI models. This ensures that your tests are reliable and meaningful.\\n* **Model optimization**: By providing insights into model performance, LangSmith's Evals helps you optimize your AI models for better results.\\n\\nOverall, LangSmith's Evals is designed to help you test and refine your AI applications more efficiently, which can lead to higher-quality results.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain_with_only_answer = (\n",
    "    RunnablePassthrough.assign(\n",
    "        context=parse_retriever_input | retriever,\n",
    "    )\n",
    "    | document_chain\n",
    ")\n",
    "\n",
    "retrieval_chain_with_only_answer.invoke(\n",
    "    {\n",
    "        \"messages\": demo_ephemeral_chat_history.messages,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21c946ed-50f0-4aff-bb4e-c2e919c7abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# We need a prompt that we can pass into an LLM to generate a transformed search query\n",
    "\n",
    "chat = ChatOllama(model=\"llama3\")\n",
    "\n",
    "query_transform_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "query_transforming_retriever_chain = RunnableBranch(\n",
    "    (\n",
    "        lambda x: len(x.get(\"messages\", [])) == 1,\n",
    "        # If only one message, then we just pass that message's content to retriever\n",
    "        (lambda x: x[\"messages\"][-1].content) | retriever,\n",
    "    ),\n",
    "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n",
    "    query_transform_prompt | chat | StrOutputParser() | retriever,\n",
    ").with_config(run_name=\"chat_retriever_chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b8ceefd-ff35-4f2e-8d98-ba4a52976e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(chat, prompt)\n",
    "\n",
    "conversational_retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=query_transforming_retriever_chain,\n",
    ").assign(\n",
    "    answer=document_chain,\n",
    ")\n",
    "\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c5fe096-a88e-4404-90ca-3a2fe5a13639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how can langsmith help with testing?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"LangSmith can help with testing through its Evals feature, which makes it easy to build and run high-quality evaluation datasets and metrics for AI applications. This allows you to test and optimize your applications more efficiently.\\n\\nWith LangSmith's Evals, you can:\\n\\n1. Create evaluation datasets: Define the inputs and expected outputs for your AI application, making it easier to test its performance.\\n2. Run evaluations: Use LangSmith's SDK or UI to run your evaluation datasets against your AI application, getting accurate results on how well it performs.\\n3. Track key metrics: View key metrics such as RPS (requests per second), error rates, and costs to monitor the performance of your AI application.\\n\\nBy leveraging LangSmith's Evals feature, you can:\\n\\n* Faster development cycles: Focus on improving your AI application's performance with reliable evaluation results.\\n* Better optimization: Make data-driven decisions by analyzing the outcomes of different approaches and models.\\n* Improved reliability: Catch issues earlier in the development process through rigorous testing.\\n\\nLangSmith's Evals empowers you to build high-quality AI applications that meet your requirements, saving time and resources.\", additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(id='8fb2ee91-7b8a-42b9-8516-91fd84728282', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.'),\n",
       "  Document(id='a45e9e58-a375-4bc5-9d9d-8f01881694f4', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Prompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.'),\n",
       "  Document(id='a62d2afe-f4c3-406a-9e70-18bbe5d96838', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started with LangSmith | 🦜️🛠️ LangSmith'),\n",
       "  Document(id='8fd2c8ce-e8d7-4dbc-a948-3d5924438bc2', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.')],\n",
       " 'answer': \"LangSmith can help with testing through its Evals feature, which makes it easy to build and run high-quality evaluation datasets and metrics for AI applications. This allows you to test and optimize your applications more efficiently.\\n\\nWith LangSmith's Evals, you can:\\n\\n1. Create evaluation datasets: Define the inputs and expected outputs for your AI application, making it easier to test its performance.\\n2. Run evaluations: Use LangSmith's SDK or UI to run your evaluation datasets against your AI application, getting accurate results on how well it performs.\\n3. Track key metrics: View key metrics such as RPS (requests per second), error rates, and costs to monitor the performance of your AI application.\\n\\nBy leveraging LangSmith's Evals feature, you can:\\n\\n* Faster development cycles: Focus on improving your AI application's performance with reliable evaluation results.\\n* Better optimization: Make data-driven decisions by analyzing the outcomes of different approaches and models.\\n* Improved reliability: Catch issues earlier in the development process through rigorous testing.\\n\\nLangSmith's Evals empowers you to build high-quality AI applications that meet your requirements, saving time and resources.\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"how can langsmith help with testing?\")\n",
    "\n",
    "response = conversational_retrieval_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages},\n",
    ")\n",
    "\n",
    "demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "595cf762-7c24-4ad5-9ea4-ad060c0bd985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how can langsmith help with testing?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"LangSmith can help with testing through its Evals feature, which makes it easy to build and run high-quality evaluation datasets and metrics for AI applications. This allows you to test and optimize your applications more efficiently.\\n\\nWith LangSmith's Evals, you can:\\n\\n1. Create evaluation datasets: Define the inputs and expected outputs for your AI application, making it easier to test its performance.\\n2. Run evaluations: Use LangSmith's SDK or UI to run your evaluation datasets against your AI application, getting accurate results on how well it performs.\\n3. Track key metrics: View key metrics such as RPS (requests per second), error rates, and costs to monitor the performance of your AI application.\\n\\nBy leveraging LangSmith's Evals feature, you can:\\n\\n* Faster development cycles: Focus on improving your AI application's performance with reliable evaluation results.\\n* Better optimization: Make data-driven decisions by analyzing the outcomes of different approaches and models.\\n* Improved reliability: Catch issues earlier in the development process through rigorous testing.\\n\\nLangSmith's Evals empowers you to build high-quality AI applications that meet your requirements, saving time and resources.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='tell me more about that!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='tell me more about that!', additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(id='8fb2ee91-7b8a-42b9-8516-91fd84728282', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.'),\n",
       "  Document(id='a62d2afe-f4c3-406a-9e70-18bbe5d96838', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started with LangSmith | 🦜️🛠️ LangSmith'),\n",
       "  Document(id='a45e9e58-a375-4bc5-9d9d-8f01881694f4', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Prompt Engineering\\u200b\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.'),\n",
       "  Document(id='8fd2c8ce-e8d7-4dbc-a948-3d5924438bc2', metadata={'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith'}, page_content='Get started by adding tracing to your application.\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.')],\n",
       " 'answer': \"Let's dive deeper into LangSmith's Evals feature and how it can help with testing your AI applications.\\n\\n**What are evaluations?**\\n\\nEvaluations in LangSmith are a set of predefined inputs, expected outputs, and evaluation metrics used to test the performance of your AI application. These evaluations help you determine how well your model is performing, identify areas for improvement, and make data-driven decisions about its development.\\n\\n**Why are evaluations important?**\\n\\nEvaluations are crucial because they allow you to:\\n\\n1. **Validate model performance**: Ensure that your AI application is producing accurate results by comparing them with expected outputs.\\n2. **Identify biases and errors**: Catch issues early on by running evaluations against different scenarios, datasets, or user inputs.\\n3. **Optimize model development**: Make data-driven decisions about improvements, such as tweaking hyperparameters, adjusting training data, or retraining the model.\\n4. **Compare models and versions**: Evaluate multiple models or versions of your AI application to determine which one performs best.\\n\\n**How do evaluations work in LangSmith?**\\n\\nLangSmith's Evals feature provides a simple way to create, run, and track evaluations for your AI applications. Here's how it works:\\n\\n1. **Define evaluation datasets**: Create predefined inputs (e.g., text prompts) and expected outputs (e.g., responses) for your AI application.\\n2. **Choose evaluation metrics**: Select relevant metrics to measure the performance of your AI application, such as accuracy, precision, recall, F1-score, or others.\\n3. **Run evaluations**: Use LangSmith's SDK or UI to execute your evaluation datasets against your AI application and generate results.\\n4. **View evaluation reports**: Get detailed reports on the performance of your AI application, including metrics like RPS (requests per second), error rates, and costs.\\n\\n**Benefits of using LangSmith's Evals**\\n\\nBy leveraging LangSmith's Evals feature, you can:\\n\\n1. **Simplify testing and optimization**: Streamline the process of testing and improving your AI applications.\\n2. **Increase development speed**: Focus on building high-quality models instead of manually writing test cases or debugging issues.\\n3. **Improve model reliability**: Catch errors and biases early on to ensure that your AI applications are trustworthy and reliable.\\n\\nLangSmith's Evals empowers you to build better AI applications, faster. Try it out today!\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"tell me more about that!\")\n",
    "\n",
    "conversational_retrieval_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8ef16-ce5a-46ff-873f-f1d3ab702aba",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/use_cases/chatbots/quickstart/#quickstart-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6f9e1-443d-421a-a95c-9bf4ee05cdec",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "1. why chaining? what is langchain doing?\n",
    "2. Embedding models - which are the popular ones?\n",
    "3. Chroma db, store the embeddings \n",
    "4. What are the alternatives to langchain? \n",
    "5. Why is Ollama required here?\n",
    "6. So we are just inferring here? what would inteference platforms like groq do?\n",
    "7. langsmith - to inspect internals?\n",
    "8. langsmith eval / test framework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57105571-3462-46e3-9c38-f76168572aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
